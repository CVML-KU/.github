# ğŸš€ CVML-KU  
### Computer Vision and Machine Intelligence Lab  
**Khalifa University**

---

## ğŸ§­ About  
The CVML Lab at Khalifa University advances robust computer vision and machine learning, developing intelligent visual systems for real-world applications in security and surveillance, biometrics, medical imaging, remote sensing, and autonomous systems.

---

# ğŸ“š Research Areas & Featured Publications

---

## ğŸ” Surveillance and Inspection  

Researching intelligent visual and audio analytics for security, environmental monitoring, and automated inspection across complex real-world environments. This includes X-ray/CT threat detection, crowd tracking, flare analysis, and robust speech-based identification in noisy public spaces.

### ğŸ“„ Featured Works

| ğŸ“˜ Title / Paper | ğŸ“ Description | ğŸ—‚ï¸ Repository | ğŸ… Venue | ğŸ¬ Demo |
|------------------|----------------|---------------|-----------|-----------|
| [**STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection**](https://arxiv.org/abs/2504.02823) | A domain-aware vision-language model to support multimodal X-ray security tasks (Grounding, VQA, and scene understanding). | [STING-BEE](https://github.com/Divs1159/STING-BEE) | CVPR'25-Highlight| [Demo](https://youtu.be/_efmQW2nSGw) |
| **STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection** | A domain-aware vision-language model to support multimodal X-ray security tasks (Grounding, VQA, and scene understanding). | Repo | CVPR'25-Highlight | Demo |
| **STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection** | A domain-aware vision-language model to support multimodal X-ray security tasks (Grounding, VQA, and scene understanding). | Repo | CVPR'25-Highlight | Demo|

---

## ğŸ©º Medical Imaging  

We develop advanced computer vision and machine learning methods for the analysis of diverse medical imaging modalities, including MRI, CT, X-ray, fundus, and digital pathology. Our work aims to build robust computational frameworks that enhance diagnostic accuracy, support quantitative interpretation, and improve clinical decision-making across healthcare applications.

### ğŸ“„ Featured Works

| ğŸ“˜ Title / Paper | ğŸ“ Description | ğŸ—‚ï¸ Repository | ğŸ… Venue | ğŸ¬ Demo |
|------------------|----------------|---------------|-----------|-----------|
| [**DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation**](https://arxiv.org/abs/2504.04566) | A dynamic uncertainty-aware semi-supervised segmentation framework for robust learning under class imbalance. | [DyCON](https://github.com/KU-CVML/DyCON)| CVPR'25| https://youtube.com/dummy-demo |
| **STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection** | A domain-aware vision-language model to support multimodal X-ray security tasks (Grounding, VQA, and scene understanding). | Repo | CVPR'25 | Demo |
| **STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection** | A domain-aware vision-language model to support multimodal X-ray security tasks (Grounding, VQA, and scene understanding). | Repo | CVPR'25 | Demo |

---

## ğŸ—‚ï¸ Other Repositories  
Tools, utilities, sandbox code, and projects.

| ğŸ—‚ï¸ Repository | ğŸ“ Description | ğŸ”— Link |
|----------------|----------------|----------|
| STING-BEE Tools | Utility tools and helper scripts for multimodal X-ray security research. | https://github.com/dummy-repo |
| STING-BEE Sandbox | Experimental code and prototypes for vision-language modeling in X-ray security. | https://github.com/dummy-repo |

---

## ğŸ“„ Publications  
You may link to:  
- Google Scholar  
- ResearchGate  
- KU faculty profile  
- Lab publications page  

---

## ğŸ“¬ Contact  
Website: (add link)  
Email: (lab or PI email)

---

## ğŸ™ Acknowledgements  
(Optional section for grants, funding bodies, or collaborators.)
# Overview
CVML-KU Organization Profile
